services:
  runner:
    image: docker.io/vladvez/telegram-ai-agent:latest
    container_name: agent-runner
    entrypoint: ["true"]
    env_file:
      - ./env/python.env
    restart: on-failure

  consumer:
    image: docker.io/vladvez/agent-consumer:latest
    container_name: agent-consumer
    depends_on:
      - runner
    env_file:
      - ./env/python.env
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: on-failure

  server:
    image: docker.io/vladvez/backend-server:latest
    container_name: backend-server
    env_file:
      - ./env/javascript.env
    expose:
      - "5000"
    restart: on-failure

  nginx:
    image: docker.io/vladvez/nginx-fe:latest
    container_name: nginx
    depends_on:
      - server
    expose:
      - "80"
    restart: on-failure

  caddy:
    image: caddy:latest
    container_name: caddy
    depends_on:
      - nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-data:/data
      - caddy-config:/config
    restart: unless-stopped

volumes:
  caddy-data:
  caddy-config:
